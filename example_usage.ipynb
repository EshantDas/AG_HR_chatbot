{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.workflow.ag_hr_chatbot import ag_hr_bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [\n",
    "    \"Let's begin with the basics. What's the job title you're hiring for?\",\n",
    "    \"Thanks! And is this position full-time, part-time, or contract?\",\n",
    "    \"Which department will this role be in?\",\n",
    "    \"Great! What defines success in this role?\",\n",
    "    \"Got it. And who will this person report to?\",\n",
    "    \"Well. Where is this position based at?\",\n",
    "    \"Can you talk about the work arrangement for this role? (Hybrid, WFH, In Office, On Field Etc.)\",\n",
    "    \"Now, let's talk about the key responsibilities. Can you describe the main duties this person will handle?\",\n",
    "    \"Got it! Would you like to add any additional tasks or responsibilities?\",\n",
    "    \"Great! What are the specific long-term goals and expectations from this position?\",\n",
    "    \"Got it! What is the immediate challenge that a new hire would face in this position?\",\n",
    "    \"Great! What defines success in this role?\",\n",
    "    \"How does this role align with and support the company's overarching strategic objectives?\",\n",
    "    \"How frequently will this individual collaborate with teams from other departments, such as marketing, sales, or customer success?\",\n",
    "    \"Who are the key stakeholders this person will regularly interact with outside the immediate team?\",\n",
    "    \"Let's cover the skills and qualifications now. What's the minimum years of experience required for this role?\",\n",
    "    \"Great! Any specific educational background or certifications needed?\",\n",
    "    \"Are there any skills you expect them to develop?\",\n",
    "    \"And are there any must-have technical skills or soft skills?\",\n",
    "    \"What type of working style thrives for this role?\",\n",
    "    \"Are there any additional qualifications or skills that would be a bonus?\",\n",
    "    \"Is there any preferred candidate background that would fit the role best?\",\n",
    "    \"What opportunities for learning and growth does this role offer?\",\n",
    "    \"What benefits will you offer with this role?\",\n",
    "    \"What kind of guidance or mentorship can the new hire expect?\",\n",
    "    \"How would you describe your management style?\",\n",
    "    \"And what's the work culture like on the team?\",\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No worries! Just let us know which department this role belongs to, like Marketing, IT, or HR. It helps candidates get a clear idea. Can you share more details?\n",
      "Got it! Could you please specify the department for this role? Like Marketing, IT, or HR? This will help us provide better context for candidates. Thanks!\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions_list[:\u001b[38;5;241m5\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(question)\n\u001b[0;32m----> 6\u001b[0m     score, reply, follow_up, chat_history, chat_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ag_hr_bot_response(\n\u001b[1;32m      7\u001b[0m         question, answer, chat_history, chat_summary\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m score \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Keep retrying while the score is 0\u001b[39;00m\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;66;03m# Ask the user to provide a new input based on the reply\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AG_Transformation/core/workflow/ag_hr_chatbot.py:38\u001b[0m, in \u001b[0;36mag_hr_bot_response\u001b[0;34m(question, answer, chat_history, chat_summary, follow_up)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mag_hr_bot_response\u001b[39m(\n\u001b[1;32m     36\u001b[0m     question, answer, chat_history, chat_summary, follow_up\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m ):\n\u001b[0;32m---> 38\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m     39\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer}\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m     chat_history\u001b[38;5;241m.\u001b[39mappend(AIMessage(content\u001b[38;5;241m=\u001b[39mquestion))\n\u001b[1;32m     42\u001b[0m     chat_history\u001b[38;5;241m.\u001b[39mappend(HumanMessage(content\u001b[38;5;241m=\u001b[39manswer))\n",
      "File \u001b[0;32m~/Desktop/AG_Transformation/myenv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3064\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3062\u001b[0m     part \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(step\u001b[38;5;241m.\u001b[39mainvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asyncio_accepts_context():\n\u001b[0;32m-> 3064\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part(), context\u001b[38;5;241m=\u001b[39mcontext)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   3065\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3066\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part())\n",
      "File \u001b[0;32m~/Desktop/AG_Transformation/myenv/lib/python3.11/site-packages/langchain_core/prompts/base.py:233\u001b[0m, in \u001b[0;36mBasePromptTemplate.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    232\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags)\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acall_with_config(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aformat_prompt_with_error_handling,\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    236\u001b[0m     config,\n\u001b[1;32m    237\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    238\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m    239\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/AG_Transformation/myenv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1976\u001b[0m, in \u001b[0;36mRunnable._acall_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1972\u001b[0m coro \u001b[38;5;241m=\u001b[39m acall_func_with_variable_args(\n\u001b[1;32m   1973\u001b[0m     func, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1974\u001b[0m )\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asyncio_accepts_context():\n\u001b[0;32m-> 1976\u001b[0m     output: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1978\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "File \u001b[0;32m~/Desktop/AG_Transformation/myenv/lib/python3.11/site-packages/langchain_core/prompts/base.py:185\u001b[0m, in \u001b[0;36mBasePromptTemplate._aformat_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_aformat_prompt_with_error_handling\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    188\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "chat_summary = []\n",
    "\n",
    "for question in questions_list[:5]:\n",
    "    answer = input(question)\n",
    "    score, reply, follow_up, chat_history, chat_summary = await ag_hr_bot_response(\n",
    "        question, answer, chat_history, chat_summary\n",
    "    )\n",
    "\n",
    "    if score == 0:\n",
    "        while score == 0:  # Keep retrying while the score is 0\n",
    "            # Ask the user to provide a new input based on the reply\n",
    "            print(reply)\n",
    "            answer = input(reply)\n",
    "        \n",
    "            score, reply, follow_up, chat_history, chat_summary = await ag_hr_bot_response(\n",
    "                question, answer, chat_history, chat_summary\n",
    "            )\n",
    "            if score != 0:  # Exit the loop if score is no longer 0\n",
    "                break\n",
    "\n",
    "    if score == 1:\n",
    "        pass  # Go to the next question\n",
    "\n",
    "    elif score == 2:\n",
    "        while score==2:  # Continue handling follow-ups until resolved\n",
    "            # Ask the follow-up question and get the user's response\n",
    "            follow_up_answer = input(follow_up)\n",
    "     \n",
    "            score, reply, follow_up, chat_history, chat_summary = await ag_hr_bot_response(\n",
    "                follow_up, follow_up_answer, chat_history, chat_summary\n",
    "            )\n",
    "            if score ==0:\n",
    "                while score == 0:  # Keep retrying while the score is 0\n",
    "                    # Ask the user to provide a new input based on the reply\n",
    "                    answer = input(reply)\n",
    "                    score, reply, follow_up, chat_history, chat_summary = await ag_hr_bot_response(\n",
    "                        question, answer, chat_history, chat_summary\n",
    "                    )\n",
    "                if score != 0:  # Exit the loop if score is no longer 0\n",
    "                    break\n",
    "\n",
    "            if score!=2:  # Exit the loop if no more follow-up questions\n",
    "                break\n",
    "\n",
    "        # Once all follow-ups are resolved, move to the next question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Question': \"Let's begin with the basics. What's the job title you're hiring for?\",\n",
       "  'Answer': 'Data and AI'},\n",
       " {'Question': 'Thanks! And is this position full-time, part-time, or contract?',\n",
       "  'Answer': 'full time'},\n",
       " {'Question': 'Which department will this role be in?',\n",
       "  'Answer': 'Artificial Intelligence'},\n",
       " {'Question': 'Got it. And who will this person report to?',\n",
       "  'Answer': 'Karan head of Data'},\n",
       " {'Question': 'Well. Where is this position based at?',\n",
       "  'Answer': 'Vataran city'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Let's begin with the basics. What's the job title you're hiring for?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Data and AI', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Thanks! And is this position full-time, part-time, or contract?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='full time', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Which department will this role be in?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hajmola anar dana', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='It seems that your answer, \"Hajmola anar dana,\" is not related to the question about which department the role will be in. Please provide the name of the department, such as \\'Data Science\\' or \\'Artificial Intelligence.\\'', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Which department will this role be in?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Artificial Intelligence', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Got it. And who will this person report to?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Karan head of Data', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Well. Where is this position based at?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Vataran city', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
